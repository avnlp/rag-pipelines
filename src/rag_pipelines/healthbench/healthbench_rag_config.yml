# HealthBench RAG Configuration

# Dataset configuration
dataset:
  path: "openai/healthbench"
  split: "test"
  question_field: "prompt"
  answer_field: "ideal_completions_data"

# Metadata schema for HealthBench clinical conversations
metadata_schema:
  properties:
    clinical_scenario:
      type: "string"
      description: "Primary clinical scenario or medical situation described"
    chief_complaint:
      type: "string"
      description: "Main symptom or reason for seeking medical attention"
    medical_specialty:
      type: "string"
      description: "Relevant medical specialty (e.g., cardiology, pediatrics, emergency medicine)"
    urgency_level:
      type: "string"
      description: "Level of medical urgency (emergency, urgent, routine, preventive)"
    patient_demographics:
      type: "string"
      description: "Patient age group, gender, or other demographic factors mentioned"
    symptom_duration:
      type: "string"
      description: "Duration or timing of symptoms if specified"
    severity_indicators:
      type: "string"
      description: "Signs of condition severity or red flags mentioned"
    diagnostic_considerations:
      type: "string"
      description: "Potential diagnoses or differential diagnoses discussed"
    treatment_approaches:
      type: "string"
      description: "Treatment options, medications, or management strategies mentioned"
    preventive_care:
      type: "string"
      description: "Preventive measures or health maintenance recommendations"
    risk_factors:
      type: "string"
      description: "Risk factors or predisposing conditions identified"
    clinical_setting:
      type: "string"
      description: "Healthcare setting (emergency room, primary care, telehealth, etc.)"
    communication_style:
      type: "string"
      description: "Style of clinical communication (empathetic, directive, educational, etc.)"
    decision_complexity:
      type: "string"
      description: "Complexity level of clinical decision making required"
    ethical_considerations:
      type: "string"
      description: "Ethical issues or considerations in the scenario"



# Embedding model
embedding:
  model_name: "Qwen/Qwen3-Embedding-0.6B"

# Contextual Reranker
reranker:
  model: "ContextualAI/ctxl-rerank-v2-instruct-multilingual-1b"
  instruction: "Prioritize Medical articles that directly answer the question."

# Vector store (Milvus)
vectorstore:
  collection_name: "healthbench"
  vector_fields: ["dense", "sparse"]
  consistency_level: "Strong"
  drop_old: false

# Retriever
retriever:
  k: 5


# Evaluation metrics:
metrics:
  contextual_recall:
    threshold: 0.7
    model: "llama-3.3-70b-versatile"
    include_reason: true
    async_mode: true

  contextual_precision:
    threshold: 0.6
    model: "llama-3.3-70b-versatile"
    include_reason: true
    async_mode: true

  contextual_relevancy:
    threshold: 0.6
    model: "llama-3.3-70b-versatile"
    include_reason: true
    async_mode: true

  answer_relevancy:
    threshold: 0.7
    model: "llama-3.3-70b-versatile"
    include_reason: true
    async_mode: true

  faithfulness:
    threshold: 0.8
    model: "llama-3.3-70b-versatile"
    include_reason: true
    async_mode: true

  g_eval:
    name: "HealthBench Alignment"
    criteria: "Evaluate if the response provides appropriate medical advice, avoids harmful recommendations, demonstrates context awareness, and follows clinical communication best practices."
    threshold: 0.8
    model: "llama-3.3-70b-versatile"
    include_reason: true
    async_mode: true

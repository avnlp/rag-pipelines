# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Retry Policy for the clients\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n\nclient<llm> GroqClient {\n  provider openai-generic\n  retry_policy Exponential\n  options {\n    base_url \"https://api.groq.com/openai/v1\"\n    api_key env.GROQ_API_KEY\n    model \"qwen/qwen3-32b\"\n    temperature 0.6\n    max_tokens 4096\n    top_p 0.95\n  }\n}\n\nclient<llm> CerebrasClient {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://api.cerebras.ai/v1\"\n    api_key env.CEREBRAS_API_KEY\n    model \"qwen-3-32b\"\n    temperature 0.6\n    max_tokens 4096\n    top_p 0.95\n  }\n}\n\nclient<llm> SambaNovaClient {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://api.sambanova.ai/v1\"\n    api_key env.SAMBANOVA_API_KEY\n    model \"qwen-3-32b\"\n    temperature 0.6\n    max_tokens 4096\n    top_p 0.95\n  }\n}\n\n\n// Fallback Client - Tries Groq, then Cerebras, then SambaNova\nclient<llm> GroqFallbackClient {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    // If Groq fails, try Cerebras, then SambaNova\n    strategy [GroqClient, CerebrasClient, SambaNovaClient]\n  }\n}\n\n",
    "earnings_calls.baml": "// Earnings Calls\n\n// The `Answer` class defines the structured output we expect from the LLM.\nclass Answer {\n  // The `chain_of_thought` field captures the LLM's reasoning process.\n  chain_of_thought string @description(\"Step-by-step reasoning for how the answer was derived from the context.\")\n  // The `summary` field contains the final, summarized answer.\n  summary string @description(\"The final, concise answer to the user's question.\")\n}\n\n// The Answer is generated based on the context and question\nfunction GenerateAnswer(context: string, question: string) -> Answer {\n  // The `GroqFallbackClient` tries a sequence of providers (Groq, then Cerebras, then SambaNova)\n  client GroqFallbackClient\n\n  // The `{{ ctx.output_format }}` uses the schema from the `Answer` class\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are an expert earnings call financial analyst. Use the retrieved context\n    to answer the question precisely. Provide a detailed and accurate\n    answer based on the provided context.\n\n    Your response MUST be in the following format:\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }}\n    Context:\n    ---\n    {{ context }}\n    ---\n\n    Question: {{ question }}\n  \"#\n}\n\ntest TestEarningsQuestion {\n  functions [GenerateAnswer]\n  args {\n    context \"In Q4 2023, Apple's revenue was $119.6 billion, driven by strong iPhone sales. The services division also saw significant growth, reaching an all-time revenue record.\"\n    question \"What was Apple's revenue in Q4 2023 and what were the main drivers?\"\n  }\n}",
    "generators.baml": "generator target {\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.214.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
    "metadata_enricher.baml": "// Metadata Enricher\n\n// Define a base dynamic class that can be extended at runtime\nclass DynamicMetadata {\n  // This class is marked as dynamic and will be modified by TypeBuilder at runtime\n  @@dynamic\n}\n\n// Define the function that will perform the extraction\n// It takes the input text and returns an instance of the DynamicMetadata class\nfunction ExtractMetadata(text: string) -> DynamicMetadata {\n  client GroqFallbackClient\n  prompt #\"\n    <instruction>\n    You are a precise metadata extraction system.\n    Extract the following fields from the provided text if they are explicitly mentioned.\n    The fields to extract are defined by the schema provided.\n    </instruction>\n\n    <input_text>\n    {{ text }}\n    </input_text>\n\n    {{ ctx.output_format }}\n    Ensure the output is valid JSON matching the specified schema.\n    Do not include fields that are not found in the text. Omit them entirely.\n \"#\n}\n\n// An empty schema will be passed here since the dynamic fields have not been defined yet\ntest TestMetadataExtraction {\n    functions [ExtractMetadata]\n    args {\n        text \"Apple Inc. reported strong results for Q3 2024. The company's revenue reached $81.8 billion, marking a significant increase. The CEO mentioned that iPhone sales drove most of the growth.\"\n    }\n}\n\n// Test case for dynamic metadata extraction with a specific schema\ntest TestDynamicMetadataExtraction {\n    functions [ExtractMetadata]\n    type_builder {\n        // Define the dynamic class based on the schema\n        dynamic class DynamicMetadata {\n          company_name string?\n          quarter string?\n          revenue float?\n          is_positive bool?\n        }\n    }\n    args {\n      text \"Apple Inc. reported strong results for Q3 2024. The company's revenue reached $81.8 billion, marking a significant increase. The CEO mentioned that iPhone sales drove most of the growth.\"\n    }\n}",
}

def get_baml_files():
    return _file_map